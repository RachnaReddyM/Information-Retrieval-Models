GOAL: Design and build your information retrieval systems, evaluate and compare their performance levels in terms of retrieval effectiveness

Developed in PYTHON 2.7
*******************************************************************************************************************************************************************

FILES SUBMITTED:

Phase1- Indexing and 4 Retrieval Models

Task1:- 

1)  corpus.py  
    to parse the given documents and queries (parses only .html documents and parses only .txt file for queries)
2)  corpus 
    folder consisting of all the parsed documents
3)  processed.queries 
    parsed queries using the cacm.query as input. This file is used as input to all the retrieval models. It is in a particular format as - QueryID(space)Query
4)  indexer.py 
    to build an inverted index using the parsed corpus
5)  Index_Unigram.txt 
    Inverted Index in the following format- 
    term-->(DOCID,TERM_FREQUENCY),(DOCID,TERM_FREQUENCY)
6)  Unigram_tokens.txt 
    contains the no. of unigrams in each document (lenght of the document), in the format-
    DOCID-->length_of_document
7)  Unigram_TF.txt
    contains the no. of times each unigram token appears in the corpus, in the format-
    term-->term_frequency_of_term_in_corpus
8)  Unigram_DF.txt
    contains the no. of documents in which each unigram token appears, in the format-
    term-->DOCID DOCID DOCID -> no._of_documents
9)  BM25.py 
    BM25 retrieval model to rank documents for each query, based on the inverted index generated by indexer.py
10) BM25_Ranking.txt 
    Output of BM25 retrieval model- top 100 documents for each query
11) tfidf.py 
    tf.idf retrieval model to rank documents for each query, based on the inverted index generated by indexer.py
12) TFiDF_Ranking.txt 
    Output of tf.idf retrieval model- top 100 documents for each query
13) QueryLikelihood.py 
    Query Likelihood retrieval model to rank documents for each query, based on the inverted index generated by indexer.py
14) Query_Likelihood_Ranking.txt 
    Output of Query Likelihood retrieval model- top 100 documents for each query
15) Lucene.java 
    Lucene- Simple Analyser to rank documents for each query, based on the inverted index generated by indexer.py
16) Lucene_result.txt 
    Output of Lucene retireval model to rank documents for each query

Task2:- Pseudo Relevance feedback performed on the results generated by the BM25 retreival model

1)BM25_PRF.py 
  BM25 run with pseudo relevance feedback
2)PRF.txt 
  Output of BM25 with pseudo relevance feedback performed


Task3:-
A) Implemented Stopping to fetch better results on each run.

1) Task3_A.py
   to create the inverted index and write processed queries to a file by ignoring the given stopped word in (common_words.txt)
2) stopped.queries.txt 
   Task3_A.py takes processed.queries.txt as input, removed the stopped words and wrote the queries back to the file in the format-
   QueryID(space)Query
3) Index_Unigram_Stopping.txt
   Inverted index without stopwords - output of Task3_A.py, in the format
   term-->(DOCID,TERM_FREQUENCY),(DOCID,TERM_FREQUENCY)
4) Unigram_tokens_Stopping.txt
   contains the no. of unigrams in each document (lenght of the document) excluding the stopwords, in the format-
   DOCID-->length_of_document
5) Unigram_TF_Stopping.txt
   contains the no. of times each unigram token appears in the corpus excluding stopwords, in the format-
   term-->term_frequency_of_term_in_corpus
6) BM25_A.py
7) tfidf_A.py
8) QueryLikelihood_A.py
9) BM25_Rankings_AfterStopping.txt
   Output of BM25 retrieval model after stopping was performed by running BM25_A.py
10) TFiDF_Rankings_AfterStopping.txt
   Output of tf.idf retrieval model after stopping was performed by running tfidf_A.py
11) Query_Likelihood_AfterStopped.txt
   Output of Query Likelihood retrieval model after stopping was performed by running QueryLikelihood_A.py

B) Implemented Stemming to fetch better results on each run.

1) Task3_B.py
   to create the inverted index using the stemmed corpus (cacm_stem.txt) and processed the queries taking cacm_stem.query.txt as input
2) cacm_stem.processed.query.txt 
   Task3_B.py takes cacm_stem.query.txt as input, the queries are formatted, and written to the cacm_stem.processed.query.txt file in the format-
   QueryID(space)Query
3) Index_Unigram_Stemmed.txt
   Inverted index of the stemmed corpus - output of Task3_A.py, in the format
   term-->(DOCID,TERM_FREQUENCY),(DOCID,TERM_FREQUENCY)
4) Unigram_tokens_Stemmed.txt
   contains the no. of unigrams in each stemmed document (lenght of the document), in the format-
   DOCID-->length_of_document
5) Unigram_TF_Stemmed.txt
   contains the no. of times each unigram token appears in the stemmed corpus, in the format-
   term-->term_frequency_of_term_in_corpus
6) BM25_B.py
7) tfidf_B.py
8) QueryLikelihood_B.py
9) BM25_Rankings_AfterStemming.txt
   Output of BM25 retrieval model on stemmed corpus, by running BM25_B.py
10) TFiDF_Rankings_AfterStemming.txt
   Output of tf.idf retrieval model on stemmed corpus, by running tfidf_B.py
12) Query_Likelihood_AfterStemming.txt
   Output of Query Likelihood retrieval model on stemmed corpus, by running QueryLikelihood_B.py


Phase2- Displaying results

1) Generate_Snippet.py
   code to generate the snippets for each results generated. This is used to display results.
2) Snippet_Output.html
   Output file for the given BM25 results.

Phase3- Evaluation

1) Phase3_Evaluation.py
   used to evaluate the generated results for each retrieval model by taking the results and cacm.rel.txt as input.
2) BM25_Ranking_Evaluation.txt
3) BM25_Rankings_AfterStopping_Evaluation.txt
4) Query_Likelihood_AfterStopped_Evaluation.txt
5) Query_Likelihood_Ranking_Evaluation.txt
6) TFiDF_Ranking_Evaluation.txt
7) TFiDF_Rankings_AfterStopping_Evaluation.txt
8) PRF_Evaluation.txt
9) Lucene_Evaluation.txt

Extra Credit- Implemented an Indexer to store Term Positions and to perform proximity-enabled search to fetch better results than the traditional retrieval models.

1) Term_Proximity_Indexer.py
   This is used to generate the Inverted index with term positions in the inverted list. It is in the format-
   term-->(DOCID,Term_Frequency,[term_position,term_position]);(DOCID,Term_Frequency,[term_position,term_position])
2) TP_Index_Unigram.txt
   Inverted index of the corpus - output of Term_Proximity_Indexer.py, in the format
   term-->(DOCID,Term_Frequency,[term_position,term_position]);(DOCID,Term_Frequency,[term_position,term_position])
3) TP_Unigram_tokens.txt
   contains the no. of unigrams in each document (lenght of the document), in the format-
   DOCID-->length_of_document
4) Term_Proximity_Indexer_Stopped.py
   This is used to generate the Inverted index excluding the stopped words given in common_words.txt with term positions in the inverted list. 
   It is in the format-
   term-->(DOCID,Term_Frequency,[term_position,term_position]);(DOCID,Term_Frequency,[term_position,term_position])
5) TP_Index_Unigram_Stopped.txt
   Inverted index of the corpus - output of Term_Proximity_Indexer_Stopped.py, in the format
   term-->(DOCID,Term_Frequency,[term_position,term_position]);(DOCID,Term_Frequency,[term_position,term_position])
6) TP_Unigram_tokens_Stopped.txt
   contains the no. of unigrams in each document exclusing stopped words (lenght of the document), in the format-
   DOCID-->length_of_document
7) Term_Proximity.py
   Retrieval model to generate the ranking of each document by considering term proximity.
8) TP_results.txt
   The top 100 documents with their rankings for each query based on the term proximity, before stopping.
9) TP_results_Stopped.txt
   The top 100 documents with their rankings for each query based on the term proximity, after stopping.

**********************************************************************************************************************************************************************************

INSTRUCTIONS:

--> Please maintain the format of each input and output files. It's important to read the file from disk and write it to memory.
--> The file extensions are fixed. The raw documents have to be in .html (to parse) and every output file or other input files should be in .txt except for snippet generation,
    the output file is in .html
--> For every user input, please make sure to give the full path of the document.
--> The retrieval models have results with Query ID, which are not always in ascending order of the Query ID.

************************************************************************************************************************************************************************************


LIBRARIES REQUIRED:

import requests
from bs4 import BeautifulSoup
import os
import re
from string import maketrans
import operator
from collections import defaultdict

*************************************************************************************************************************************************************************************
Note: Please give the full path while giving the input path when asked

HOW TO RUN THE FILES:

1)  corpus.py

--> Please give the following input when asked-

"Please enter the full path where the raw documents are present For which parsing needs to be done"
....\Cacm_corpus
"Please enter the full path where the processed query terms to be stored"
....\Processed_query.txt

2) BM25.py

for phase1-task1:

"Please enter the full path where the processed queries are present"
....\processed.queries.txt
"Please enter the full path where the inverted index is present"
....\Index_unigrams.txt
"Please enter the full path where the unigram tokens are present"
....\unigram_tokens.txt
"Please enter the full path, along with text file name, where the BM25 results need to be stored"
....\BM25.txt

3) BM25_A.py
for phase1-task3 A:

"Please enter the full path where the processed queries are present"
....\stopped.queries.txt
"Please enter the full path where the inverted index is present"
....\Index_Unigram_Stopping.txt
"Please enter the full path where the unigram tokens are present"
....\Unigram_tokens_Stopping.txt
"Please enter the full path, along with text file name, where the BM25 results need to be stored"
....\BM25_Rankings_AfterStopping.txt

4) BM25_B.py
for phase1-task3 B:

"Please enter the full path where the processed queries are present"
....\cacm_stem.processed.query.txt
"Please enter the full path where the inverted index is present"
....\Index_Unigram_Stemmed.txt
"Please enter the full path where the unigram tokens are present"
....\Unigram_tokens_Stemmed.txt
"Please enter the full path, along with text file name, where the BM25 results need to be stored"
....\BM25_Rankings_AfterStemming.txt

5) tfidf.py

for phase1-task1:

"Please enter the full path where the processed queries are present"
....\processed.queries
"Please enter the full path where the inverted index is present"
....\Index_unigrams.txt
"Please enter the full path where the unigram tokens are present"
....\unigram_tokens.txt
Please enter the full path, along with text file name, where the tf.idf results need to be stored
....\TFiDF_Ranking.txt

6) tfidf_A.py
for phase1-task3 A:

"Please enter the full path where the processed queries are present"
....\stopped.queries.txt
"Please enter the full path where the inverted index is present"
....\Index_Unigram_Stopping.txt
"Please enter the full path where the unigram tokens are present"
....\Unigram_tokens_Stopping.txt
"Please enter the full path, along with text file name, where the tf.idf results need to be stored"
....\TFiDF_Rankings_AfterStopping.txt

7) tfidf_B.py
for phase1-task3 B:

"Please enter the full path where the processed queries are present"
....\cacm_stem.processed.query.txt
"Please enter the full path where the inverted index is present"
....\Index_Unigram_Stemmed.txt
"Please enter the full path where the unigram tokens are present"
....\Unigram_tokens_Stemmed.txt
"Please enter the full path, along with text file name, where the tf.idf results need to be stored"
....\TFiDF_Rankings_AfterStemming.txt

8) Query_Likelihood.py

for phase1-task1:

"Please enter the full path where the processed queries are present"
....\processed.queries
"Please enter the full path where the inverted index is present"
....\Index_unigrams.txt
"Please enter the full path where the unigram tokens are present"
....\unigram_tokens.txt
"Please enter the full path, along with text file name, where the unigram term frequencies are stored for each term in corpus"
....\Unigram_TF.txt
Please enter the full path, along with text file name, where the Query_Likelihood results need to be stored
....\Query_Likelihood_Ranking.txt

9) Query_Likelihood_A.py
for phase1-task3 A:

"Please enter the full path where the processed queries are present"
....\stopped.queries.txt
"Please enter the full path where the inverted index is present"
....\Index_Unigram_Stopping.txt
"Please enter the full path where the unigram tokens are present"
....\Unigram_tokens_Stopping.txt
"Please enter the full path, along with text file name, where the unigram term frequencies are stored for each term in corpus"
....\Unigram_TF_Stopping.txt
"Please enter the full path, along with text file name, where the Query_Likelihood results need to be stored"
....\Query_Likelihood_AfterStopped.txt

10) Query_Likelihood_B.py
for phase1-task3 B:

"Please enter the full path where the processed queries are present"
....\cacm_stem.processed.query.txt
"Please enter the full path where the inverted index is present"
....\Index_Unigram_Stemmed.txt
"Please enter the full path where the unigram tokens are present"
....\Unigram_tokens_Stemmed.txt
"Please enter the full path, along with text file name, where the unigram term frequencies are stored for each term in corpus"
....\Unigram_TF_Stemmed.txt
"Please enter the full path, along with text file name, where the Query_Likelihood results need to be stored"
....\Query_Likelihood_AfterStemming.txt

11) BM25_PRF.py 

 for phase1-task2:
 
"Please enter the full path where the processed queries are present"
....\processed.queries.txt
"Please enter the full path where the inverted index is present"
....\Index_unigrams.txt
"Please enter the full path where the unigram tokens are present"
....\unigram_tokens.txt
"Please enter the full path where the common words/stopwords are present"
....\common_words.txt
"Please enter the full path, along with text file name, where the BM25 results need to be stored"
....\PRF.txt

12) Generate_Snippet.py

** In the code, please put the required paths for the variables defined globally as mentioned below:

for phase2:

variable_name                           path(Example)
	
corpus_path                             ....\corpus
query_path                              ....\processed.queries.txt
BM25_Result_Path		        ....\BM25_snippet_results.html

14) Phase3_Evaluation.py

for phase3:
"Please enter the full path where the relevance document is present"
....\cacm.rel.txt
"Please enter the full path where the ranking doc to be evaluated is present"
....\Query_Likelihood_AfterStopped.txt
"Please enter the full path where the evaluation result is to be stored along with the file name"
....\Query_Likelihood_AfterStopped_Evaluation.txt

15) Lucene.java

for phase1-task1:

"Enter the FULL path where the index will be created:"
....\index\
"Enter the FULL path to add into the index"
....\corpus\
"Enter the File name with the location containing the query terms"
....\processed.queries.txt

16) Term_Proximity

for extra credit task:

A) without stopping:

"Please enter the full path where the processed queries are present"
....\processed.queries.txt
"Please enter the full path where the inverted index is present"
....\TP_Index_Unigram.txt
"Please enter the full path where the unigram tokens are present"
....\TP_Unigram_tokens.txt
"Please enter the full path, along with text file name, where the Term_Proximity results need to be stored"
....\TP_results.txt

B) with stopping:

"Please enter the full path where the processed queries are present"
....\stopped.queries.txt
"Please enter the full path where the inverted index is present"
....\TP_Index_Unigram_Stopped.txt
"Please enter the full path where the unigram tokens are present"
....\TP_Unigram_tokens_Stopped.txt
"Please enter the full path, along with text file name, where the Term_Proximity results need to be stored"
....\TP_results_Stopped.txt




   

